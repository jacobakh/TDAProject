---
title: "TDA Analysis"
author: "Yakub Akhmerov"
date: "May 9, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(TDA)
```

Intro:
I began the semester with a lingering feeling of immersing myself into something intellectually stimulating. I stumbled across topology in my Real Analysis course fall of 2017. I generally enjoyed working on it and noticed the beautiful generalized, objective theory behind it. Since my field is data science and analytics, I figured it would be appropriate to combine two fields which I am genuinely interested in and go from through. Thus, I stumbled upon topological data analysis. 

I reached out to several profession sources and eventually stumbled upon Dmitriy Mozorov at the Berkeley Institute of Data Science. He advised me in this research and was a great in my concrete understanding of the subject.
To demonstrate my new found abilities in topological data analysis, I choose to apply  my understanding to a project.

############################################
## Topological Data Analysis  ##
## Problem: How well can TDA be used on cyrptocurrency data?
## Testing on Binance API Data
## Description: We provide daily cryptocurrency data (transaction count, on-chain transaction volume, value of created coins, price, market cap, and exchange volume) in CSV format. The data sample stretches back to December 2013. We explain the column titles and some shortcomings here.
Source: https://coinmetrics.io/data-downloads/
##  ID sample code number (not unique).
#V1 date: Date on georgian calender.
#V2 txVolume(USD): “on-chain transaction volume.” Essentially a broad and largely unadjusted measure of the total value of outputs on the blockchain, on a given day.
#V3 txCount: Number of transactions happening on the public blockchain a day. The is a broad estimation. More can be explained in the source as to why that is.
#V4  marketcap(USD): The unit price multiplied by the number of units in circulation.
#V5 Price: Open price, received from CoinMarketCap.
#V6 exchangevolume(USD): The dollar value of the volume at exchanges. Also received from CoinMarketCap.
#V7 generatedCoins: The number of new coins that have been brought into existence on that day
#V8 Fees: Fees. One important peice of information is that the fees in this data are based on the native currency, not USD.

############################################

 

############################################
## Toying with Topological Data Analysis  ##
## Testing on   Biopsy Data on Breast Cancer Patients
## source : http://vincentarelbundock.github.io/Rdatasets/doc/MASS/biopsy.html
## Description This breast cancer database was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg. He assessed biopsies of breast tumours for 699 patients up to 15 July 1992; each of nine attributes has been scored on a scale of 1 to 10, and the outcome is also known. There are 699 rows and 11 columns.
##  ID sample code number (not unique).
#V1 clump thickness.
#V2 uniformity of cell size.
#V3 uniformity of cell shape.
#V4 marginal adhesion.
#V5 single epithelial cell size.
#V6 bare nuclei (16 values are missing).
#V7 bland chromatin.
#V8 normal nucleoli.
#V9 mitoses.
#class = outcome >  "benign" or "malignant". (B or M)
############################################
#install.packages("phom") and the rest
```{r}
library(diffusionMap)
library(randomForest)
library(ggplot2)
library(reshape)
library(reshape2)  ## here is where we do a 'pivot table'
library(plyr)
library(phom)

### (1) Let's begin with Diffusion Map

setwd("~/Downloads/")

btc = read.csv("btc.csv", header = T) 
btc$ID <- seq.int(nrow(btc))
btc[1] <- btc$ID
eth = read.csv("eth.csv")
eth$date = as.Date(eth$date, "%m/%d/%Y")

head(btc) # see header to decode V1-V9;  b = benign; M = malignant
summary(btc)

## what we are starting with 

## WARNING - this big task choked my computer - may want to skip this line
plot(eth$price.USD.)
plot(btc[1:10], main="biopsy data set", pch=23, bg = c("red", "green")
     [unclass(biopsy$outcome)])


data <- biopsy[1:9] ## let's learn off the first 4 columns
outcome <- biopsy$outcome ## and species is our target and classifier 

D = dist(scale(data)) # use Euclidean distance on data
## DIST: This function computes and returns the distance matrix computed by using the specified distance measure to compute the distances between the rows of a data matrix.

## DIFFUSE: Description : Uses the pair-wise distance matrix for a data set to compute the diffusion map coefficients. Computes the Markov transition probability matrix, and its eigenvalues and left & right eigenvectors. Returns a 'dmap' object.
# Usage - diffuse(D, eps.val = epsilonCompute(D), neigen = NULL, t = 0, maxdim = 50, delta=10^-5)
# Arguments D - n-by-n pairwise distance matrix for a data set with n points, or alternatively output from the dist() function
# eps.val     epsilon parameter for the diffusion weight matrix, exp(-D$^2$/(eps.val)). Default is to use the epsilon corresponding to the median distance to the 0.01*n nearest neighbor
# neigen - number of dimensions of final diffusion map representation. Default uses number of dimensions corresponding to a 95% drop-off in eigenvalue multiplier.
# t     optional time-scale parameter in the diffusion map. The (recommended) default uses multiscale geometry.

dmap = diffuse(D, eps.val=10, t=1, neigen=2) ## just run with the standard default settings
plot(dmap$X[,1],dmap$X[,2],col=outcome,pch=paste(outcome), 
     xlab="Diffusion Map Coordinate 1", 
     ylab="Diffusion Map Coordinate 2",
     main="Diffusion Map of U.Wisc Biopsy Data EPS10")
## not ideal

dmap = diffuse(D,eps.val=400, t=1, neigen=2)
## if this works, you should see clusters of malignent and benign 
plot(dmap$X[,1],dmap$X[,2],col=outcome,pch=paste(outcome), 
     xlab="Diffusion Map Coordinate 1", 
     ylab="Diffusion Map Coordinate 2",
     main="Diffusion Map of U.Wisc Biopsy Data EPS400")
## yes, good  

# 2) OK - now Use random forest "Department" classifier to define distances

fit = randomForest(data, outcome, ntree=20, proximity=TRUE) 
print(fit)
varImpPlot(fit)
## V2, V6 and V3 seem to be  is dominant driver =
   #V2 uniformity of cell size.
   #V6 bare nuclei (16 values are missing).
   #V3 uniformity of cell shape.

# PLOT 3
#version
D2 = 1-fit$proximity # use 1 - proximity
dmap2 = diffuse(D2,eps.val=40, t=.01, neigen=2)   #original dmap1 = diffuse(D1,eps.val=.1, t=1, neigen=2)
head(dmap2)

cluster2 = hclust(dist(dmap2$X[,1:2]))
plot(cluster2); abline(h=1.8, col='blue',lwd=3)

## PLOT 5
plot(dmap2$X[,1],dmap2$X[,2],col=outcome,pch=paste(outcome), 
     xlab="Diffusion Map Coordinate 1", 
     ylab="Diffusion Map Coordinate 2")

#PLOT 6
## clustering variable 4 (Plot 7) vs 10 is interesting
## depends what you want to output
clustering2 = cutree(cluster2,k=10)  ## this is how many nodes there are
clustering2

plot(dmap2$X[,1],dmap2$X[,2],col=clustering2, pch=19,
     xlab="Diffusion Map Coordinate 1", 
     ylab="Diffusion Map Coordinate 2", 
     main="Biopsy Data - Starting to look Interesting")

## See plot 8 - note number of 'buckets' 

output2 = data.frame(dmap2$X,outcome,clustering2)
colnames(output2)[4] <- "group"  ## rename column
head(output2)

write.csv(output2,"TDA_export_biopsy.csv") 
## may look at this in D3 or Google Fusion


#####################################
# 3) Try 1/proximity - 1 instead - PLOT 9
fit3 = randomForest(data, outcome, ntree=100, proximity=TRUE) 

D3 = 1./fit3$proximity - 1. # use 1/proximity - 1
dmap3 = diffuse(D3,eps.val=400, t=1, neigen=2) 
plot(dmap3$X[,1],dmap3$X[,2],col=outcome,pch=paste(outcome), 
     xlab="Diffusion Map Coordinate 1", 
     ylab="Diffusion Map Coordinate 2",
     main = "Biopsy Data 1/prox RF")
## using RF method we generate  plot similar to plot 6 (but better focus)

cluster3 = hclust(dist(dmap3$X[,1:2]))
plot(cluster3); abline(h=.6, col='green',lwd=3)
## probably overfitting here

BINS = 12
clustering3 = cutree(cluster3,k=BINS)  ## this is how many nodes there are
clustering3

plot(dmap3$X[,1],dmap3$X[,2],col=clustering3, pch=19,
     xlab="Diffusion Map Coordinate 1", 
     ylab="Diffusion Map Coordinate 2")
## Plot 10

#### Nice - this looks like somehting we can stitch together and ascribe weight to - 

## fixed?
output3 = data.frame(dmap3$X,outcome,clustering3)
head(output3)
melted <- melt(output3, measure = "clustering3", id = c("outcome"))
head(melted)
print(cast(melted, value ~ ., sum)) ## useful to show pivot, but not valid add

gold <- print(cast(melted, value ~ ., sum)) ## useful to show pivot, but not valid add
colnames(gold)[1] <- "cluster"
colnames(gold)[2] <- "count"
## we sum all, so still need to divide by number of samples in each bin
gold$count <- gold$count / gold$cluster
gold ## ok - here is count of each 'bin'

melted <- melt(output3, measure = "X1", id = c("clustering3"))
head(melted)
silver <- print(cast(melted, clustering3 ~ ., sum)) ## useful to show pivot, but not valid add
colnames(silver)[2] <- "sum"
silver
silver$sum <- silver$sum / gold$count # this sound divide total sum of coodinate by count of them, to give average
silver ## ok, here is our X1 center of gravity
gold
gold$x <- silver$sum

## and the long winded way to do it for X2 (Y coordinate)
melted <- melt(output3, measure = "X2", id = c("clustering3"))
head(melted)
silver <- print(cast(melted, clustering3 ~ ., sum)) ## useful to show pivot, but not valid add
colnames(silver)[2] <- "sum"
silver
silver$sum <- silver$sum / gold$count # this sound divide total sum of coodinate by count of them, to give average
silver ## ok, here is our X1 center of gravity
gold$y <- silver$sum  ## here is Y cooridnates
gold  ## Ok, we have a BINS (e.g. 12) number of baskets, with a count and a center of gravity
## this is good data to do a bubble chart (weight is count;)

## google fusion does not like negatives - excel is fine -(depends on where you want to wrok with x y cooridnate data)
#gold$x <- gold$x + 1 # can omit if you like
#gold$y <- gold$y + 1 # can omit if you like - shifts x y coordinates up and over by 1 - non negative

write.csv(gold,"TDA_export_bubble_gold.csv") 

## or can do in R - http://lamages.blogspot.com/2012/03/googlevis-0215-is-released-improved-geo.html
## Gradient colour example

#install.packages("googleVis")  ##
library(googleVis)

### IF BLANK IN LITTLE WINDOW in R STUDIO
## THEN HIT THE EXPAND BUTTON AND SHOULD SHOW UP IN FULL SCREEN - served by , for example, http://127.0.0.1:25271/custom/googleVis/LineChartID8dc4e42125d.html 

####### THIS WORKS!
goldBubble <- gvisBubbleChart(gold, idvar="cluster", xvar="x", yvar="y",
                           colorvar="count", sizevar="count",
                           options=list(
                             title='Biopsy Clustered Data - TDA Exploration',
                             hAxis='{minValue:-1, maxValue:4}',
                             vAxis='{minValue:-1, maxValue:4}'
                            )
)
plot(goldBubble) ## to see it expand R studio viewer to full screen
######## takes gold and plots bubble chart from google vis in R environment :)
## if you want to work with 'gold' outside of R (eg. google fusion or excel)
write.csv(gold,"TDA_export_data3.csv") 

 

# using smoothed histograms
D4 = dist(data)
# dmap4 = diffuse(D4,eps.val=50, t=1, neigen=2)  # works pretty good with biopsy mythica
dmap4 = diffuse(D4,eps.val=50, t=1, neigen=2) 
head(dmap4)
plot(dmap4$X[,1],dmap4$X[,2],col=outcome,pch=paste(outcome), 
     xlab="Diffusion Map Coordinate 1", 
     ylab="Diffusion Map Coordinate 2", ylim=c(-2,2))

# fit RF on smoothed histograms
fit4 = randomForest(data, outcome, ntree=50, proximity=TRUE)
## 1000 is too much - overfitting
print(fit4)

 

 

 

############### LAST BIT NOT WORKING YET - NO BARCODES FOR BIOPSY XXXXXXXXXX

############### LAST BIT NOT WORKING YET - NO BARCODES FOR BIOPSY XXXXXXXXXX

########## some pHO for good measure
### Source http://blog.revolutionanalytics.com/2014/01/topological-data-analysis-with-r.html 
## (5) Betti where are you? - See Plot 4
data5 <- as.matrix(data)
#data5 <- as.matrix(data[,-5])
dim(data5)
head(data5)
max_dim <- 0
max_f <- 1

GoldInt0 <- pHom(data5, 
                 dimension=max_dim,              # maximum dimension of persistent homology computed
                 max_filtration_value=max_f,     # maximum dimension of filtration complex
                 mode="vr",                      # type of filtration complex
                 metric="euclidean")

plotBarcodeDiagram(GoldInt0, max_dim, max_f, title="H0 Barcode plot Biopsy Data")
#not working well

